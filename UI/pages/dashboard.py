"""
P√°gina: Dashboard de Estad√≠sticas
Visualizaci√≥n de datos y an√°lisis del sistema OCR

Elementos de Streamlit:
- ‚úÖ st.metric: M√©tricas visuales con deltas
- ‚úÖ st.bar_chart / st.line_chart: Gr√°ficos nativos
- ‚úÖ st.dataframe: Tablas interactivas
- ‚úÖ st.pyplot: Gr√°ficos matplotlib
- ‚úÖ Session State: Datos persistentes
- ‚úÖ st.columns: Layout responsive
"""
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sys
sys.path.append('..')
from utils.api_utils import verificar_api
from utils.sidebar_common import render_sidebar

st.title("üìä Dashboard de Estad√≠sticas")
st.markdown("### An√°lisis visual del sistema OCR")

# Renderizar sidebar com√∫n
render_sidebar()

# Verificar si hay datos
if 'historial_reconocimientos' not in st.session_state or len(st.session_state.historial_reconocimientos) == 0:
    st.info("""
    ### üì≠ Sin datos a√∫n
    
    El dashboard mostrar√° estad√≠sticas una vez que realices reconocimientos de texto.
    
    **Para empezar:**
    1. Ve a cualquier p√°gina de reconocimiento (üìù üì∑ üìÅ)
    2. Procesa algunas im√°genes
    3. Vuelve aqu√≠ para ver an√°lisis visuales
    
    ¬°Las estad√≠sticas se actualizan autom√°ticamente! üìà
    """)
    st.stop()

# Cargar datos del historial
# Justificaci√≥n: Session state para persistencia de datos entre sesiones
historial = st.session_state.historial_reconocimientos
stats = st.session_state.estadisticas

# KPIs principales
# Justificaci√≥n: M√©tricas visuales para mostrar indicadores clave de rendimiento
st.markdown("### üéØ Indicadores Clave")
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric(
        "Total Reconocimientos",
        stats['total_reconocimientos'],
        delta=f"+{len(historial)} hoy" if len(historial) > 0 else None,
        help="N√∫mero total de im√°genes procesadas"
    )

with col2:
    st.metric(
        "Caracteres Procesados",
        stats['total_caracteres'],
        delta=f"{stats['total_caracteres']/max(stats['total_reconocimientos'],1):.1f} por imagen",
        help="Total de caracteres reconocidos"
    )

with col3:
    conf_actual = np.mean([h['confianza_promedio'] for h in historial]) if historial else 0
    st.metric(
        "Confianza Promedio",
        f"{conf_actual*100:.1f}%",
        delta=f"{(conf_actual - 0.96)*100:+.1f}% vs modelo" if conf_actual > 0 else None,
        help="Confianza promedio del modelo (96% esperado)"
    )

with col4:
    idiomas_unicos = len(stats['idiomas_detectados'])
    st.metric(
        "Idiomas Detectados",
        idiomas_unicos,
        help="N√∫mero de idiomas diferentes identificados"
    )

st.markdown("---")

# Gr√°ficos de an√°lisis
# Justificaci√≥n: Visualizaci√≥n de tendencias y patrones en los datos
col_left, col_right = st.columns(2)

with col_left:
    st.markdown("### üìà Confianza por Reconocimiento")
    
    # Preparar datos para el gr√°fico
    if historial:
        df_confianza = pd.DataFrame([
            {
                'Reconocimiento': i+1,
                'Confianza': h['confianza_promedio'] * 100
            }
            for i, h in enumerate(historial)
        ])
        
        # Justificaci√≥n: Line chart para mostrar evoluci√≥n temporal
        st.line_chart(df_confianza.set_index('Reconocimiento'))
        st.caption("Evoluci√≥n de la confianza del modelo a lo largo del tiempo")
    else:
        st.info("Sin datos para mostrar")

with col_right:
    st.markdown("### üåç Distribuci√≥n de Idiomas")
    
    if stats['idiomas_detectados']:
        # Justificaci√≥n: Bar chart para comparar categor√≠as
        df_idiomas = pd.DataFrame([
            {'Idioma': idioma, 'Cantidad': count}
            for idioma, count in stats['idiomas_detectados'].items()
        ])
        st.bar_chart(df_idiomas.set_index('Idioma'))
        st.caption("Frecuencia de idiomas detectados")
    else:
        st.info("Sin datos de idiomas")

# Distribuci√≥n de longitud de textos
st.markdown("### üìè Distribuci√≥n de Longitud de Textos")

if historial:
    # Justificaci√≥n: Matplotlib para gr√°ficos personalizados avanzados
    longitudes = [len(h['texto']) for h in historial]
    
    fig, ax = plt.subplots(figsize=(10, 4))
    ax.hist(longitudes, bins=20, edgecolor='black', alpha=0.7, color='#1f77b4')
    ax.set_xlabel('Longitud (caracteres)')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Distribuci√≥n de Longitud de Textos Reconocidos')
    ax.grid(True, alpha=0.3)
    
    st.pyplot(fig)
    st.caption(f"Longitud promedio: {np.mean(longitudes):.1f} caracteres | Min: {min(longitudes)} | Max: {max(longitudes)}")
else:
    st.info("Sin datos para distribuci√≥n")

# Tabla detallada del historial
# Justificaci√≥n: Dataframe interactivo para exploraci√≥n detallada de datos
st.markdown("---")
st.markdown("### üìã Historial Detallado")

if historial:
    df_historial = pd.DataFrame([
        {
            'ID': i+1,
            'Texto': h['texto'][:30] + '...' if len(h['texto']) > 30 else h['texto'],
            'Longitud': h.get('num_caracteres', len(h['texto'])),
            'Confianza': f"{h['confianza_promedio']*100:.1f}%",
            'Idioma': h.get('idioma', 'N/A'),
            'Timestamp': h['timestamp'].strftime('%H:%M:%S') if 'timestamp' in h else 'N/A'
        }
        for i, h in enumerate(historial)
    ])
    
    # Configurar dataframe con columnas espec√≠ficas
    st.dataframe(
        df_historial,
        use_container_width=True,
        hide_index=True,
        column_config={
            "ID": st.column_config.NumberColumn("ID", help="N√∫mero de reconocimiento"),
            "Texto": st.column_config.TextColumn("Texto Reconocido", help="Vista previa del texto"),
            "Longitud": st.column_config.NumberColumn("Caracteres", help="N√∫mero de caracteres"),
            "Confianza": st.column_config.TextColumn("Confianza", help="Nivel de confianza"),
            "Idioma": st.column_config.TextColumn("Idioma", help="Idioma detectado"),
            "Timestamp": st.column_config.TextColumn("Hora", help="Momento del reconocimiento")
        }
    )
else:
    st.info("Sin historial disponible")

# An√°lisis de caracteres m√°s comunes
st.markdown("---")
st.markdown("### üî§ An√°lisis de Caracteres")

if historial:
    col_chars, col_stats = st.columns([2, 1])
    
    with col_chars:
        # Contar frecuencia de caracteres
        todos_caracteres = ''.join([h['texto'] for h in historial])
        from collections import Counter
        contador = Counter(todos_caracteres.replace(' ', ''))  # Excluir espacios
        
        # Top 10 caracteres m√°s comunes
        if contador:
            top_chars = dict(contador.most_common(10))
            df_chars = pd.DataFrame([
                {'Car√°cter': char, 'Frecuencia': freq}
                for char, freq in top_chars.items()
            ])
            
            st.bar_chart(df_chars.set_index('Car√°cter'))
            st.caption("Top 10 caracteres m√°s reconocidos")
        else:
            st.info("Sin datos de caracteres")
    
    with col_stats:
        st.markdown("**Estad√≠sticas:**")
        total_chars = len(todos_caracteres)
        chars_unicos = len(set(todos_caracteres))
        
        st.metric("Total Caracteres", total_chars)
        st.metric("√önicos", chars_unicos)
        st.metric("Espacios", todos_caracteres.count(' '))
        
        # Calcular diversidad
        diversidad = chars_unicos / total_chars if total_chars > 0 else 0
        st.metric("Diversidad", f"{diversidad*100:.1f}%")

# Controles del dashboard
st.markdown("---")
st.markdown("### ‚öôÔ∏è Controles")

col_ctrl1, col_ctrl2, col_ctrl3 = st.columns(3)

with col_ctrl1:
    # Justificaci√≥n: Widget para exportar datos (funcionalidad futura)
    if st.button("üì• Exportar Datos", use_container_width=True, disabled=True):
        st.info("Funcionalidad de exportaci√≥n disponible pr√≥ximamente")

with col_ctrl2:
    # Justificaci√≥n: Limpiar datos para reiniciar an√°lisis
    if st.button("üóëÔ∏è Limpiar Historial", use_container_width=True, type="secondary"):
        if st.session_state.get('confirmar_limpieza', False):
            st.session_state.historial_reconocimientos = []
            st.session_state.estadisticas = {
                'total_reconocimientos': 0,
                'total_caracteres': 0,
                'idiomas_detectados': {}
            }
            st.session_state.confirmar_limpieza = False
            st.success("‚úÖ Historial limpiado")
            st.rerun()
        else:
            st.session_state.confirmar_limpieza = True
            st.warning("‚ö†Ô∏è Haz clic de nuevo para confirmar")

with col_ctrl3:
    # Estado de la API
    if verificar_api():
        st.success("‚úÖ API Activa")
    else:
        st.error("‚ùå API Inactiva")

# Informaci√≥n sobre el dashboard
with st.expander("‚ÑπÔ∏è Sobre este Dashboard"):
    st.markdown("""
    ### üìä Dashboard de An√°lisis OCR
    
    **Objetivo**: Proporcionar insights visuales sobre el uso y rendimiento del sistema.
    
    **Elementos de Streamlit utilizados:**
    
    1. **`st.metric()`**: Indicadores clave con deltas
       - Justificaci√≥n: Visualizaci√≥n r√°pida de KPIs importantes
    
    2. **`st.line_chart()`**: Evoluci√≥n de confianza
       - Justificaci√≥n: Mostrar tendencias temporales
    
    3. **`st.bar_chart()`**: Distribuci√≥n de idiomas y caracteres
       - Justificaci√≥n: Comparar categor√≠as visualmente
    
    4. **`st.pyplot()`**: Histograma personalizado
       - Justificaci√≥n: Gr√°ficos avanzados con matplotlib
    
    5. **`st.dataframe()`**: Tabla interactiva del historial
       - Justificaci√≥n: Exploraci√≥n detallada de datos
    
    6. **Session State**: Persistencia de estad√≠sticas
       - Justificaci√≥n: Mantener datos entre interacciones
    
    **Datos recopilados:**
    - Texto reconocido (solo para estad√≠sticas)
    - Confianza del modelo
    - Idioma detectado
    - Timestamp de procesamiento
    
    **Privacidad**: Los datos solo se almacenan en memoria durante la sesi√≥n.
    
    ¬°Todas las visualizaciones se actualizan autom√°ticamente! üìà
    """)
